"""
Real Metric Agent for RCA Data Collection - Using Real MCP Data
"""
import logging
from datetime import datetime
from typing import List, Dict, Any
from tools.paas_entity_tools import umodel_get_entities
from tools.paas_data_tools import umodel_get_golden_metrics
from ..utils.evidence_chain import EvidenceChain
import ast

class MinimalMetricAgent:
    """Minimal metric agent for data collection - æ”¯æŒç¦»çº¿æ¨¡å¼."""
    
    def __init__(self, debug: bool = False, offline_mode: bool = False, problem_id: str = None):
        self.debug = debug
        self.offline_mode = offline_mode
        self.problem_id = problem_id
        self.logger = logging.getLogger(__name__)
        if offline_mode:
            # ç¦»çº¿æ¨¡å¼ï¼šä½¿ç”¨æœ¬åœ°æ•°æ®åŠ è½½å™¨
            from ..utils.local_data_loader import get_local_data_loader
            self.local_loader = get_local_data_loader(debug=debug)
            self.logger.info(f"âœ… MinimalMetricAgentåˆå§‹åŒ–å®Œæˆ (ç¦»çº¿æ¨¡å¼, é—®é¢˜ID: {problem_id})")
        else:
            
            self.logger.info(f"âœ… MinimalMetricAgentåˆå§‹åŒ–å®Œæˆ (åœ¨çº¿æ¨¡å¼)")
        
        # Service to Entity ID mapping (cached)
        self._service_entity_mapping = None
        
        # APM service list (å…±ç”¨)
        self.apm_services = ["accounting", "ad", "cart", "checkout", "currency", 
                            "email", "fraud-detection","frontend", "frontend-proxy", 
                            "frontend-web", "image-provider", "inventory","payment", 
                            "product-catalog", "quote", "recommendation", "shipping"]
        
    def _get_service_entity_mapping(self, start_time: datetime, end_time: datetime) -> Dict[str, str]:
        """Get service name to entity ID mapping (cached)."""
        if self._service_entity_mapping is not None:
            return self._service_entity_mapping
            
        if self.offline_mode:
            self.logger.info("âš ï¸ ç¦»çº¿æ¨¡å¼ä¸éœ€è¦æœåŠ¡å®ä½“æ˜ å°„")
            return {}
        self._service_entity_mapping = {}
        try:
            # ä½¿ç”¨umodel_get_entitiesè·å–APMæœåŠ¡å®ä½“
            # ä½¿ç”¨é—®é¢˜çš„å®é™…æ—¶é—´èŒƒå›´ - å¿…é¡»æä¾›ï¼
            from_ts = int(start_time.timestamp())
            to_ts = int(end_time.timestamp())
            self.logger.info(f"ğŸ” ä½¿ç”¨é—®é¢˜æ—¶é—´èŒƒå›´æŸ¥è¯¢æœåŠ¡å®ä½“: {start_time} ~ {end_time}")
            
            query_params = {
                "domain": "apm",
                "entity_set_name": "apm.service",
                "from_time": from_ts,
                "to_time": to_ts
            }
            
            result = umodel_get_entities.invoke(query_params)
            
            self.logger.info(f"ğŸ“Š serviceæŸ¥è¯¢ç»“æœ: error={result.error if result else 'No result'}, æœ‰data={bool(result and result.data)}")
            
            if result and not result.error and result.data:
                content = result.data
                self.logger.info(f"ğŸ” serviceå“åº”contenté¡¹æ•°: {len(content)}")
                self.logger.info(f"ğŸ” æ‰¾åˆ°service_records: {len(content)}æ¡è®°å½•")                    
                for item in content:
                    self._service_entity_mapping[item['service']] = item['__entity_id__']
                    
                if self.debug:                                
                    self.logger.info(f"ğŸ“Š {item['service']}: ({item['__entity_id__']})")
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–æœåŠ¡å®ä½“æ˜ å°„å¤±è´¥: {e}")
            return {}

        # è¿”å›æŒ‰Podç»„ç»‡çš„K8sæŒ‡æ ‡æ•°æ®
        self.logger.info(f"âœ… serviceæ”¶é›†å®Œæˆ: {len(self._service_entity_mapping.keys())}ä¸ªservice")
        return self._service_entity_mapping
                    
        
    def _try_fetch_k8s_golden_metrics(self, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """Fetch real K8s golden metrics with application pod identification."""
        if self.offline_mode:
            self.logger.info("âš ï¸ K8sæŒ‡æ ‡åœ¨ç¦»çº¿æ¨¡å¼ä¸‹ä¸é€šè¿‡æ­¤æ–¹æ³•è·å–ï¼Œåº”ç”±_fetch_metric_dataå¤„ç†")
            return {}
        
        try:
            start_ts = int(start_time.timestamp())
            end_ts = int(end_time.timestamp())
            
            # ç¬¬1æ­¥ï¼šè·å–podå®ä½“ä¿¡æ¯ä»¥å»ºç«‹åº”ç”¨æ˜ å°„
            pod_app_mapping = self._get_pod_application_mapping(start_ts, end_ts)
            
            
            # ç¬¬2æ­¥ï¼šè·å–K8s golden metrics
            if 'business_apps' not in pod_app_mapping:
                self.logger.warning("âš ï¸ æœªæ‰¾åˆ°ä¸šåŠ¡åº”ç”¨æ˜ å°„")
                return {}
            
            self.logger.info(f"ğŸ” K8sæ•°æ®æŸ¥è¯¢")
            self.logger.info(f"   ğŸ• æ—¶é—´èŒƒå›´: {start_time} ~ {end_time} ({start_ts} ~ {end_ts})")
            self.logger.info(f"   ğŸ• æ—¶é—´æˆ³å·®å¼‚: {end_ts - start_ts}ç§’ ({(end_ts - start_ts)/60:.1f}åˆ†é’Ÿ)")
            
            k8s_metrics = {}
            
            for app, pods in pod_app_mapping['business_apps'].items():
                if app not in self.apm_services:
                    continue
                k8s_metrics[app] = {}
                self.logger.info(f"ğŸ” æŸ¥æ‰¾{app}çš„metrics_records...")
                
                for pod in pods:
                    k8s_metrics[app][pod['name']] = {}
                    k8s_metrics[app][pod['name']]['entity_id'] = pod['entity_id']
                    self.logger.info(f"ğŸ” æŸ¥æ‰¾{pod['name']}çš„metrics_records...")
                    
                    query_params = {    
                        "domain": "k8s",
                        "entity_set_name": "k8s.pod",
                        "entity_ids": [pod['entity_id']],
                        "from_time": start_ts,
                        "to_time": end_ts
                    }

                    result = umodel_get_golden_metrics.invoke(query_params)
                    
                    # Parse real metrics response
                    self.logger.info(f"ğŸ“Š K8sæŸ¥è¯¢ç»“æœ: error={result.error if result else 'No result'}, æœ‰data={bool(result and result.data)}")
                    
                    if result and not result.error and result.data:
                        content = result.data
                        self.logger.info(f"ğŸ” K8så“åº”contenté¡¹æ•°: {len(content)}")
                        self.logger.info(f"ğŸ” æ‰¾åˆ°metrics_records: {len(content)}æ¡è®°å½•")                    
                        
                        for item in content:
                            # ğŸ”§ ä¿®å¤ï¼šç›´æ¥æŒ‰podç»„ç»‡K8sæ—¶é—´åºåˆ—æ•°æ®ï¼Œä¿ç•™æ—¶é—´æˆ³å’Œpodæ ‡è¯†
                            pod_metrics = {"values": [], "timestamps": []}
                            pod_metrics['values'] = ast.literal_eval(item.get('__value__', '[0]'))
                            pod_metrics['timestamps'] = ast.literal_eval(item.get('__ts__', '[0]'))
                            k8s_metrics[app][pod['name']][item['metric']] = pod_metrics  
                            
                            if self.debug:                                
                                self.logger.info(f"ğŸ“Š {app} ({pod['name']}) - {item['metric']}: {len(pod_metrics['values'])}ä¸ªæ•°æ®ç‚¹")

            # è¿”å›æŒ‰Podç»„ç»‡çš„K8sæŒ‡æ ‡æ•°æ®
            self.logger.info(f"âœ… K8sæŒ‡æ ‡æ”¶é›†å®Œæˆ: {len(k8s_metrics)}ä¸ªåº”ç”¨, {sum(len(pod_data) for pod_data in k8s_metrics.values())}ä¸ªPod")
            return k8s_metrics
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to fetch K8s metrics with app info: {e}")
            return {}
    
    def _get_pod_application_mapping(self, start_ts: int, end_ts: int) -> Dict[str, Dict]:
        """è·å–podåˆ°åº”ç”¨çš„æ˜ å°„å…³ç³»"""
        business_apps = {}
        if self.offline_mode:
            return {"business_apps": {}}
        
        try:
            
            query_params = {
                "domain": "k8s",
                "entity_set_name": "k8s.pod",
                "from_time": start_ts,
                "to_time": end_ts,
                "limit": 1000
            }

            
            result = umodel_get_entities.invoke(query_params)

            self.logger.info(f"ğŸ“Š K8sæŸ¥è¯¢ç»“æœ: error={result.error if result else 'No result'}, æœ‰data={bool(result and result.data)}")
            

            if result and not result.error and result.data:
                content = result.data
                self.logger.info(f"ğŸ” K8så“åº”contenté¡¹æ•°: {len(content)}")
                self.logger.info(f"ğŸ” æ‰¾åˆ°podå®ä½“: {len(content)}æ¡è®°å½•")                    
                
                for item in content:
                    if item['namespace'] != 'cms-demo':
                        continue
                    pod_name = item.get('name', '')
                    entity_id = item.get('__entity_id__', '')
                    entity_type = item.get('__entity_type__', '')
                    # ä½¿ç”¨æ–°å‡½æ•°æ¸…ç†podåç§°ï¼Œæå–æœåŠ¡åç§°
                    app_name = self._clean_pod_name_to_service(pod_name)
                    
                    if app_name not in business_apps:
                        business_apps[app_name] = []
                    
                    business_apps[app_name].append({
                                            'name': pod_name,
                        'entity_id': entity_id,
                        'entity_type': entity_type
                    })

                    if self.debug:                                
                        self.logger.info(f"ğŸ“Š Podæ˜ å°„: {pod_name} -> {app_name} (entity_id: {entity_id})")
                

                return {"business_apps": business_apps}
            else:
                return {"business_apps": {}}
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–Podåº”ç”¨æ˜ å°„å¤±è´¥: {e}")
            return {"business_apps": {}}

    def _clean_pod_name_to_service(self, pod_name: str) -> str:
        """ä»podåç§°ä¸­æå–æœåŠ¡åç§°ï¼Œå»é™¤K8sç”Ÿæˆçš„åç¼€
        
        Examples:
            'cart-ds-6kgk6' -> 'cart' (DaemonSetæ ¼å¼)
            'cart-7d8f6c4b5d-xyz12' -> 'cart' (Deploymentæ ¼å¼)
            'cart-abc123' -> 'cart' (ä¸€èˆ¬æ ¼å¼)
            'loongcollector-ds-6kgk6' -> 'loongcollector'
            'frontend-proxy-asdfaasdf-23r23r' -> 'frontend-proxy'
        """
        import re
        
        # æ¨¡å¼1: DaemonSetæ ¼å¼ 'name-ds-xxxxx'
        ds_match = re.match(r'^(.+?)-ds-[a-z0-9]+$', pod_name)
        if ds_match:
            if self.debug:
                self.logger.info(f"ğŸ” DaemonSetæ¨¡å¼åŒ¹é…: {pod_name} -> {ds_match.group(1)}")
            return ds_match.group(1)
        
        # æ¨¡å¼2: Deploymentæ ¼å¼ 'name-xxxxxxxxx-xxxxx' (åŒå±‚éšæœºåç¼€)
        deployment_match = re.match(r'^(.+?)-[a-z0-9]{8,}-[a-z0-9]{5}$', pod_name)
        if deployment_match:
            if self.debug:
                self.logger.info(f"ğŸ” Deploymentæ¨¡å¼åŒ¹é…: {pod_name} -> {deployment_match.group(1)}")
            return deployment_match.group(1)
        
        # æ¨¡å¼3: ä¸€èˆ¬æ ¼å¼ 'name-xxxxx' (å•å±‚éšæœºåç¼€ï¼Œè‡³å°‘5ä¸ªå­—ç¬¦)
        general_match = re.match(r'^(.+?)-[a-z0-9]{5,}$', pod_name)
        if general_match:
            if self.debug:
                self.logger.info(f"ğŸ” ä¸€èˆ¬æ¨¡å¼åŒ¹é…: {pod_name} -> {general_match.group(1)}")
            return general_match.group(1)
                
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•æ¨¡å¼ï¼Œè¿”å›åŸåç§°
        if self.debug:
            self.logger.warning(f"âš ï¸ æ— æ³•è§£æpodåç§°: {pod_name}ï¼Œè¿”å›åŸåç§°")
        return pod_name

    def _extract_service_from_pod(self, pod_name: str) -> str:
        """ä»podåç§°ä¸­æ¨æ–­ä¸šåŠ¡åº”ç”¨åç§°"""
        # é¦–å…ˆæ¸…ç†podåç§°ï¼Œå»é™¤K8såç¼€
        clean_name = self._clean_pod_name_to_service(pod_name)
        
        # ä¸šåŠ¡æœåŠ¡æ˜ å°„è§„åˆ™ - åŸºäºå®é™…è§‚å¯Ÿçš„podå‘½åè§„å¾‹
        # ä¼˜åŒ–ï¼šå¢åŠ ç²¾ç¡®åŒ¹é…å’Œéƒ¨åˆ†åŒ¹é…çš„ä¼˜å…ˆçº§
        service_patterns = {
            'payment': ['payment', 'pay'],
            'checkout': ['checkout', 'order'],
            'inventory': ['inventory', 'stock'],
            'cart': ['cart', 'shopping', 'shopping-cart'],
            'ad': ['ad', 'advertisement', 'ads'],
            'frontend': ['frontend', 'web', 'ui', 'frontend-proxy'],
            'user': ['user', 'account', 'auth'],
            'product': ['product', 'catalog'],
            'recommendation': ['recommendation', 'recommend', 'suggestion'],
            'shipping': ['shipping', 'delivery'],
            'loongcollector': ['loongcollector', 'collector'],
            'fraud-detection': ['fraud-detection', 'fraud'],
            'currency': ['currency', 'curr'],
            'email': ['email', 'mail']
        }
        
        clean_lower = clean_name.lower()
        
        # ç¬¬ä¸€è½®ï¼šç²¾ç¡®åŒ¹é…ä¼˜å…ˆï¼ˆé¿å…å­å­—ç¬¦ä¸²è¯¯åŒ¹é…ï¼‰
        for service, patterns in service_patterns.items():
            for pattern in patterns:
                if clean_lower == pattern:
                    if self.debug:
                        self.logger.info(f"ğŸ¯ ç²¾ç¡®åŒ¹é…: {clean_name} -> {service}")
                    return service
        
        # ç¬¬äºŒè½®ï¼šéƒ¨åˆ†åŒ¹é…ï¼ˆä¿æŒå‘åå…¼å®¹æ€§ï¼‰
        for service, patterns in service_patterns.items():
            for pattern in patterns:
                if pattern in clean_lower:
                    if self.debug:
                        self.logger.info(f"ğŸ” éƒ¨åˆ†åŒ¹é…: {clean_name} -> {service} (é€šè¿‡æ¨¡å¼: {pattern})")
                    return service
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ç‰¹å®šæœåŠ¡ï¼Œä½¿ç”¨æ¸…ç†åçš„åç§°
        parts = clean_name.replace('-', '_').split('_')
        for part in parts:
            if part in ['biz', 'demo', 'k8s', 'pod']:
                continue
            if len(part) > 2:  # è¿‡æ»¤å¤ªçŸ­çš„éƒ¨åˆ†
                return part
        
        # é»˜è®¤è¿”å›æ¸…ç†åçš„åç§°æˆ–generic
        return clean_name if clean_name else "generic"

    def _try_fetch_apm_golden_metrics(self, service_name: str, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """Fetch real APM service metrics using umodel_get_golden_metrics."""
        if self.offline_mode:
            self.logger.info("âš ï¸ APMæŒ‡æ ‡åœ¨ç¦»çº¿æ¨¡å¼ä¸‹ä¸é€šè¿‡æ­¤æ–¹æ³•è·å–ï¼Œåº”ç”±_fetch_metric_dataå¤„ç†")
            return {}
        
        try:
            start_ts = int(start_time.timestamp())
            end_ts = int(end_time.timestamp())
            
            # è·å–æœåŠ¡å®ä½“æ˜ å°„
            
            service_mapping = self._get_service_entity_mapping(start_time, end_time)
            if not service_mapping or service_name not in service_mapping:
                self.logger.warning(f"âš ï¸ æœåŠ¡ '{service_name}' æœªæ‰¾åˆ°å®ä½“æ˜ å°„")
                return {}
                
            entity_id = service_mapping[service_name]
            self.logger.info(f"ğŸ” APMæ•°æ®æŸ¥è¯¢: {service_name} -> {entity_id}")
            
            # ä½¿ç”¨umodel_get_golden_metricså·¥å…·
            query_params = {
                "domain": "apm",
                "entity_set_name": "apm.service",
                "entity_ids": [entity_id],
                "from_time": start_ts,
                "to_time": end_ts
            }
            
            result = umodel_get_golden_metrics.invoke(query_params)
            
            # Parse APM metrics response
            self.logger.info(f"ğŸ“Š APMæŸ¥è¯¢ç»“æœ: error={result.error if result else 'No result'}")
            
            if result and not result.error and result.data:
                content = result.data
                self.logger.info(f"ğŸ” APMå“åº”contenté¡¹æ•°: {len(content)}")
                
                apm_metrics = {service_name: {'entity_id': entity_id}}
                
                for item in content:
                    metric_name = item.get('metric', 'unknown')
                    apm_metrics[service_name][metric_name] = {
                        'values': ast.literal_eval(item.get('__value__', '[0]')),
                        'timestamps': ast.literal_eval(item.get('__ts__', '[0]'))
                    }
                    
                    if self.debug:
                        self.logger.info(f"ğŸ“Š {service_name} - {metric_name}: APMæŒ‡æ ‡æ”¶é›†")
                
                return apm_metrics
            else:
                self.logger.warning(f"âš ï¸ {service_name}: APMæŒ‡æ ‡è·å–å¤±è´¥")
                return {}
            
        except Exception as e:
            self.logger.error(f"âŒ APMæŒ‡æ ‡è·å–å¼‚å¸¸ {service_name}: {e}")
            return {}

    def _fetch_metric_data(self, start_time: datetime, end_time: datetime) -> Dict[str, Any]:
        """æ ¹æ®æ¨¡å¼è·å–æŒ‡æ ‡æ•°æ®"""
        if self.offline_mode:
            # ç¦»çº¿æ¨¡å¼ï¼šä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ•°æ®
            if not self.problem_id:
                self.logger.error("âŒ ç¦»çº¿æ¨¡å¼éœ€è¦æŒ‡å®šproblem_id")
                return {"k8s_metrics": {}, "apm_metrics": {}}
            
            # åˆ¤æ–­æ˜¯æ•…éšœæœŸè¿˜æ˜¯åŸºçº¿æœŸæ•°æ®  
            duration_minutes = (end_time - start_time).total_seconds() / 60
            data_type = "failure" if duration_minutes <= 10 else "baseline"
            
            self.logger.info(f"ğŸ“ˆ ä»æœ¬åœ°åŠ è½½ {self.problem_id} {data_type} æŒ‡æ ‡æ•°æ®")
            metric_data = self.local_loader.load_metrics(self.problem_id, data_type)
            
            return {
                'k8s_golden_metrics': metric_data.get("k8s_metrics", {}),
                'apm_service_metrics': metric_data.get("apm_metrics", {})
            }
        else:
            # åœ¨çº¿æ¨¡å¼ï¼šä»MCPæœåŠ¡è·å–æ•°æ®
        # Fetch K8s golden metrics
            k8s_metrics = self._try_fetch_k8s_golden_metrics(start_time, end_time)
        
        # Fetch APM service metrics for key services
        apm_metrics = {}
        key_services = self.apm_services
        
        for service in key_services:
            apm_metrics[service] = {}
            # æ–°å‡½æ•°ä¸€æ¬¡æ€§è·å–ä¸€ä¸ªæœåŠ¡çš„æ‰€æœ‰æŒ‡æ ‡
            service_metrics = self._try_fetch_apm_golden_metrics(service, start_time, end_time)                                
            if service_metrics and service in service_metrics:
                service_data = service_metrics[service]
                # åªæå–ç›®æ ‡æŒ‡æ ‡
                target_metrics = ["request_count", "error_count", "avg_request_latency_seconds"]
                
                for metric in target_metrics:
                    if metric in service_data and isinstance(service_data[metric], dict):
                        # æå–valuesåˆ—è¡¨ä»¥ä¿æŒåŸæœ‰æ ¼å¼å…¼å®¹æ€§
                        metric_data = service_data[metric]
                        if 'values' in metric_data:
                            apm_metrics[service][metric] = {
                                "values": metric_data['values'],
                                "timestamps": metric_data['timestamps']
                            }
        
        return {
            'k8s_golden_metrics': k8s_metrics,
            'apm_service_metrics': apm_metrics
        }
        
    def analyze(self, evidence_chain: EvidenceChain) -> Dict[str, Any]:
        """åˆ†ææŒ‡æ ‡æ•°æ® - æ”¯æŒç¦»çº¿æ¨¡å¼"""
        mode_desc = "ç¦»çº¿æ¨¡å¼" if self.offline_mode else "åœ¨çº¿æ¨¡å¼"
        self.logger.info(f"ğŸ“Š å¼€å§‹æŒ‡æ ‡åˆ†æ ({mode_desc})")
        
        # è·å–æŒ‡æ ‡æ•°æ®
        metric_data = self._fetch_metric_data(evidence_chain.start_time, evidence_chain.end_time)
        
        # æå–ç»Ÿè®¡ä¿¡æ¯
        k8s_metrics = metric_data.get('k8s_golden_metrics', {})
        apm_metrics = metric_data.get('apm_service_metrics', {})
        
        k8s_count = sum(len(pod_data) for app_data in k8s_metrics.values() for pod_data in app_data.values() if isinstance(pod_data, dict))
        apm_count = len(apm_metrics)
        
        # è®°å½•è¯æ®
        evidence_chain.add_evidence('metric', f'{mode_desc}_metric_analysis', metric_data, confidence=0.8)
        
        self.logger.info(f"âœ… æŒ‡æ ‡åˆ†æå®Œæˆ ({mode_desc})")
        self.logger.info(f"   K8sæŒ‡æ ‡: {k8s_count}ä¸ª")
        self.logger.info(f"   APMæŒ‡æ ‡: {apm_count}ä¸ª")
        
        return {
            'k8s_metrics_count': k8s_count,
            'apm_metrics_count': apm_count,
            'k8s_apps': len(k8s_metrics),
            'apm_services': len(apm_metrics),
            'total_metrics': k8s_count + apm_count
        }
